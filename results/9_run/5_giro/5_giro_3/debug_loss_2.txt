Inizio traning con:  {'name_model': 'meta-llama/Llama-2-7b-hf', 'eightbit': False, 'name_dataset': 'wikitext', 'device': 'cuda', 'target_sparsity': 0.3, 'ppl_tolerance_frac': 0.2, 'beta': 0.8, 'R_limit': 60, 'num_searches': 64, 'top_k': 64, 'C': 1.5, 'batch_size': 48, 'num_iterations': 40, 'num_selfPlay_iterations': 50, 'num_epochs': 10, 'kl_threshold': 0.5, 'root_dir_eps': 0.15, 'root_dir_alpha': 0.3, 'lr': 0.0002, 'entropy_bonus': 0.02, 'grad_clip': 1.0, 'mcts_batch_size': 128}
[utils] meta-llama/Llama-2-7b-hf:    21748 blocchi da 64 neuroni
PPL baseline: 9.17


modellio compilato e pront! 
--> inizio ad imparare


--- Iteration 0: Self-Play ---
--- Iteration 0: Training (Avg Reward: 2.2785) ---
[Iter 0  Ep 1]  pol=5.2173  val=93.5473  ent=-3.4759
[Iter 0  Ep 2]  pol=4.8145  val=27.3877  ent=-3.4319
[Iter 0  Ep 3]  pol=5.0868  val=2.5436  ent=-3.4087
[Iter 0  Ep 4]  pol=4.9087  val=6.7214  ent=-3.4682
[Iter 0  Ep 5]  pol=4.8184  val=11.2525  ent=-3.4379
[Iter 0  Ep 6]  pol=4.6852  val=12.1220  ent=-3.4624
[Iter 0  Ep 7]  pol=4.9585  val=8.3372  ent=-3.4658
[Iter 0  Ep 8]  pol=4.4998  val=6.7464  ent=-3.4221
[Iter 0  Ep 9]  pol=4.7275  val=5.6399  ent=-3.4688
[Iter 0  Ep 10]  pol=4.7539  val=3.7864  ent=-3.4783

--- Iteration 1: Self-Play ---
--- Iteration 1: Training (Avg Reward: 2.3897) ---
[Iter 1  Ep 1]  pol=4.6226  val=3.7794  ent=-3.4621
[Iter 1  Ep 2]  pol=4.7425  val=3.8146  ent=-3.4778
[Iter 1  Ep 3]  pol=4.8233  val=4.2204  ent=-3.4350
[Iter 1  Ep 4]  pol=4.8519  val=3.0878  ent=-3.4320
[Iter 1  Ep 5]  pol=4.9967  val=1.4506  ent=-3.4957
[Iter 1  Ep 6]  pol=4.8430  val=0.7433  ent=-3.4301
[Iter 1  Ep 7]  pol=4.6692  val=2.4043  ent=-3.4823
[Iter 1  Ep 8]  pol=4.8459  val=6.2702  ent=-3.4642
[Iter 1  Ep 9]  pol=4.6682  val=9.3363  ent=-3.4478
[Iter 1  Ep 10]  pol=4.6141  val=10.7639  ent=-3.4573

--- Iteration 2: Self-Play ---
--- Iteration 2: Training (Avg Reward: 2.1387) ---
[Iter 2  Ep 1]  pol=4.9919  val=10.7036  ent=-3.4479
[Iter 2  Ep 2]  pol=4.9799  val=10.0928  ent=-3.4957
[Iter 2  Ep 3]  pol=4.8566  val=5.3128  ent=-3.4159
[Iter 2  Ep 4]  pol=4.8508  val=1.9025  ent=-3.4806
[Iter 2  Ep 5]  pol=4.9315  val=0.7966  ent=-3.4771
[Iter 2  Ep 6]  pol=4.3735  val=1.2509  ent=-3.5485
[Iter 2  Ep 7]  pol=4.9978  val=1.7031  ent=-3.5384
[Iter 2  Ep 8]  pol=4.8290  val=2.2209  ent=-3.4923
[Iter 2  Ep 9]  pol=4.6250  val=1.5122  ent=-3.4845
[Iter 2  Ep 10]  pol=5.1327  val=1.7699  ent=-3.4884

--- Iteration 3: Self-Play ---
--- Iteration 3: Training (Avg Reward: 2.1491) ---
[Iter 3  Ep 1]  pol=4.5983  val=1.6034  ent=-3.5258
[Iter 3  Ep 2]  pol=5.0487  val=1.7424  ent=-3.5042
[Iter 3  Ep 3]  pol=4.5736  val=1.7838  ent=-3.5082
[Iter 3  Ep 4]  pol=5.0305  val=1.3409  ent=-3.5660
[Iter 3  Ep 5]  pol=4.8363  val=0.9625  ent=-3.4796
[Iter 3  Ep 6]  pol=4.8374  val=0.8090  ent=-3.5039
[Iter 3  Ep 7]  pol=5.1893  val=1.9543  ent=-3.5378
[Iter 3  Ep 8]  pol=5.0440  val=3.6920  ent=-3.4960
[Iter 3  Ep 9]  pol=4.8609  val=4.5421  ent=-3.5538
[Iter 3  Ep 10]  pol=4.6577  val=3.9142  ent=-3.5316

--- Iteration 4: Self-Play ---
--- Iteration 4: Training (Avg Reward: 2.3972) ---
[Iter 4  Ep 1]  pol=5.0659  val=3.1915  ent=-3.5013
[Iter 4  Ep 2]  pol=4.8456  val=1.0003  ent=-3.5688
[Iter 4  Ep 3]  pol=4.7866  val=0.9170  ent=-3.5249
[Iter 4  Ep 4]  pol=4.7983  val=1.2129  ent=-3.5589
[Iter 4  Ep 5]  pol=4.8147  val=0.9397  ent=-3.5852
[Iter 4  Ep 6]  pol=4.5258  val=1.0114  ent=-3.5303
[Iter 4  Ep 7]  pol=4.6598  val=1.0727  ent=-3.6117
[Iter 4  Ep 8]  pol=5.0115  val=0.6851  ent=-3.5257
[Iter 4  Ep 9]  pol=4.7979  val=0.9263  ent=-3.5984
[Iter 4  Ep 10]  pol=4.6298  val=0.8295  ent=-3.5542

--- Iteration 5: Self-Play ---
--- Iteration 5: Training (Avg Reward: 2.1157) ---
[Iter 5  Ep 1]  pol=4.8261  val=1.1779  ent=-3.5912
[Iter 5  Ep 2]  pol=4.9128  val=1.1911  ent=-3.5544
[Iter 5  Ep 3]  pol=4.9099  val=1.5658  ent=-3.6034
[Iter 5  Ep 4]  pol=4.7659  val=1.3063  ent=-3.6064
[Iter 5  Ep 5]  pol=4.8415  val=1.0896  ent=-3.5745
[Iter 5  Ep 6]  pol=4.6919  val=1.1193  ent=-3.5391
[Iter 5  Ep 7]  pol=4.6512  val=1.2358  ent=-3.5547
[Iter 5  Ep 8]  pol=4.8821  val=1.4052  ent=-3.5793
[Iter 5  Ep 9]  pol=4.7596  val=1.1217  ent=-3.6283
[Iter 5  Ep 10]  pol=4.7635  val=1.1907  ent=-3.6488

--- Iteration 6: Self-Play ---
--- Iteration 6: Training (Avg Reward: 2.0586) ---
[Iter 6  Ep 1]  pol=4.7543  val=1.4889  ent=-3.6438
[Iter 6  Ep 2]  pol=4.6206  val=1.8958  ent=-3.6711
[Iter 6  Ep 3]  pol=4.7530  val=1.0430  ent=-3.6867
[Iter 6  Ep 4]  pol=4.5042  val=1.3519  ent=-3.6686
[Iter 6  Ep 5]  pol=4.9018  val=2.2968  ent=-3.6578
[Iter 6  Ep 6]  pol=4.6475  val=1.8628  ent=-3.7038
[Iter 6  Ep 7]  pol=4.3936  val=2.2717  ent=-3.7047
[Iter 6  Ep 8]  pol=4.7012  val=1.8003  ent=-3.7065
[Iter 6  Ep 9]  pol=4.6637  val=1.9900  ent=-3.7096
[Iter 6  Ep 10]  pol=4.3242  val=1.5636  ent=-3.6861

--- Iteration 7: Self-Play ---
--- Iteration 7: Training (Avg Reward: 2.2952) ---
[Iter 7  Ep 1]  pol=4.5593  val=0.7934  ent=-3.6549
[Iter 7  Ep 2]  pol=4.4281  val=0.9856  ent=-3.7006
[Iter 7  Ep 3]  pol=4.2974  val=0.9414  ent=-3.7027
[Iter 7  Ep 4]  pol=4.4658  val=1.1888  ent=-3.7175
[Iter 7  Ep 5]  pol=4.5339  val=0.9851  ent=-3.7164
[Iter 7  Ep 6]  pol=4.4048  val=1.0237  ent=-3.7044
[Iter 7  Ep 7]  pol=4.6129  val=1.0276  ent=-3.7095
[Iter 7  Ep 8]  pol=4.5872  val=1.0969  ent=-3.7006
[Iter 7  Ep 9]  pol=4.5671  val=1.3229  ent=-3.7163
[Iter 7  Ep 10]  pol=4.6856  val=0.7813  ent=-3.7107

--- Iteration 8: Self-Play ---
--- Iteration 8: Training (Avg Reward: 2.2473) ---
[Iter 8  Ep 1]  pol=4.5670  val=1.3011  ent=-3.7366
[Iter 8  Ep 2]  pol=4.5371  val=1.0219  ent=-3.7563
[Iter 8  Ep 3]  pol=4.6599  val=1.0735  ent=-3.7762
[Iter 8  Ep 4]  pol=4.2517  val=1.1840  ent=-3.7450
[Iter 8  Ep 5]  pol=4.5801  val=0.9947  ent=-3.7751
[Iter 8  Ep 6]  pol=4.4361  val=1.2596  ent=-3.7878
[Iter 8  Ep 7]  pol=4.5009  val=1.1009  ent=-3.7574
[Iter 8  Ep 8]  pol=4.4333  val=0.9528  ent=-3.7659
[Iter 8  Ep 9]  pol=4.5456  val=1.2789  ent=-3.7610
[Iter 8  Ep 10]  pol=4.3845  val=1.2087  ent=-3.7878

--- Iteration 9: Self-Play ---
--- Iteration 9: Training (Avg Reward: 2.3916) ---
[Iter 9  Ep 1]  pol=4.4672  val=0.9002  ent=-3.7866
[Iter 9  Ep 2]  pol=4.3130  val=1.1299  ent=-3.7660
[Iter 9  Ep 3]  pol=4.5094  val=1.1651  ent=-3.7683
[Iter 9  Ep 4]  pol=4.6825  val=1.2377  ent=-3.7727
[Iter 9  Ep 5]  pol=4.4679  val=1.0883  ent=-3.7772
[Iter 9  Ep 6]  pol=4.3996  val=1.2090  ent=-3.8025
[Iter 9  Ep 7]  pol=4.4260  val=1.1058  ent=-3.7886
[Iter 9  Ep 8]  pol=4.5597  val=1.5583  ent=-3.7899
[Iter 9  Ep 9]  pol=4.5431  val=1.3136  ent=-3.8134
[Iter 9  Ep 10]  pol=4.3036  val=0.9638  ent=-3.7823

--- Iteration 10: Self-Play ---
--- Iteration 10: Training (Avg Reward: 2.3472) ---
[Iter 10  Ep 1]  pol=4.4893  val=1.5850  ent=-3.7948
[Iter 10  Ep 2]  pol=4.4603  val=1.6061  ent=-3.7961
[Iter 10  Ep 3]  pol=4.4798  val=1.3258  ent=-3.7937
[Iter 10  Ep 4]  pol=4.4862  val=1.0133  ent=-3.7783
[Iter 10  Ep 5]  pol=4.4360  val=0.8005  ent=-3.8064
[Iter 10  Ep 6]  pol=4.5745  val=0.8372  ent=-3.8024
[Iter 10  Ep 7]  pol=4.4631  val=0.7825  ent=-3.8226
[Iter 10  Ep 8]  pol=4.2800  val=0.4336  ent=-3.7954
[Iter 10  Ep 9]  pol=4.2438  val=0.3635  ent=-3.8425
[Iter 10  Ep 10]  pol=4.2901  val=0.5224  ent=-3.8018

--- Iteration 11: Self-Play ---
--- Iteration 11: Training (Avg Reward: 2.2088) ---
[Iter 11  Ep 1]  pol=4.4759  val=0.9420  ent=-3.7987
[Iter 11  Ep 2]  pol=4.4955  val=0.9278  ent=-3.8168
[Iter 11  Ep 3]  pol=4.0985  val=1.1662  ent=-3.8201
[Iter 11  Ep 4]  pol=4.3427  val=1.0814  ent=-3.8224
[Iter 11  Ep 5]  pol=4.1998  val=0.9881  ent=-3.7881
[Iter 11  Ep 6]  pol=4.3247  val=1.2501  ent=-3.8034
[Iter 11  Ep 7]  pol=4.6205  val=1.1887  ent=-3.7933
[Iter 11  Ep 8]  pol=4.3875  val=3.4848  ent=-3.7926
[Iter 11  Ep 9]  pol=4.3626  val=5.6746  ent=-3.8230
[Iter 11  Ep 10]  pol=4.2280  val=5.2138  ent=-3.8336

--- Iteration 12: Self-Play ---
--- Iteration 12: Training (Avg Reward: 2.2996) ---
[Iter 12  Ep 1]  pol=4.3927  val=3.9474  ent=-3.8250
[Iter 12  Ep 2]  pol=4.4355  val=2.6608  ent=-3.8126
[Iter 12  Ep 3]  pol=4.4314  val=1.1954  ent=-3.8151
[Iter 12  Ep 4]  pol=4.4390  val=0.7787  ent=-3.8412
[Iter 12  Ep 5]  pol=4.3192  val=1.2956  ent=-3.8117
[Iter 12  Ep 6]  pol=4.5177  val=0.9234  ent=-3.8478
[Iter 12  Ep 7]  pol=4.5488  val=2.2722  ent=-3.8460
[Iter 12  Ep 8]  pol=4.2355  val=2.0455  ent=-3.8356
[Iter 12  Ep 9]  pol=4.4459  val=0.9201  ent=-3.8235
[Iter 12  Ep 10]  pol=4.1046  val=0.7766  ent=-3.8376

--- Iteration 13: Self-Play ---
--- Iteration 13: Training (Avg Reward: 2.2748) ---
[Iter 13  Ep 1]  pol=4.4785  val=0.9237  ent=-3.8684
[Iter 13  Ep 2]  pol=4.4540  val=0.8691  ent=-3.8129
[Iter 13  Ep 3]  pol=4.3167  val=0.9964  ent=-3.8414
[Iter 13  Ep 4]  pol=4.3606  val=0.9032  ent=-3.8360
[Iter 13  Ep 5]  pol=4.3313  val=0.8191  ent=-3.8179
[Iter 13  Ep 6]  pol=4.4053  val=1.5373  ent=-3.8520
[Iter 13  Ep 7]  pol=4.5096  val=2.1109  ent=-3.8524
[Iter 13  Ep 8]  pol=4.3337  val=3.1497  ent=-3.8362
[Iter 13  Ep 9]  pol=4.5352  val=2.7449  ent=-3.8603
[Iter 13  Ep 10]  pol=4.4635  val=2.6515  ent=-3.8357

--- Iteration 14: Self-Play ---
--- Iteration 14: Training (Avg Reward: 2.2120) ---
[Iter 14  Ep 1]  pol=4.4234  val=1.7144  ent=-3.8306
[Iter 14  Ep 2]  pol=4.2439  val=1.3692  ent=-3.8356
[Iter 14  Ep 3]  pol=4.3257  val=1.4252  ent=-3.8297
[Iter 14  Ep 4]  pol=4.3059  val=1.9880  ent=-3.8480
[Iter 14  Ep 5]  pol=4.4900  val=1.9759  ent=-3.8409
[Iter 14  Ep 6]  pol=4.4143  val=2.9331  ent=-3.8566
[Iter 14  Ep 7]  pol=4.4540  val=3.0305  ent=-3.8490
[Iter 14  Ep 8]  pol=4.5672  val=2.3965  ent=-3.8485
[Iter 14  Ep 9]  pol=4.4096  val=1.0930  ent=-3.8517
[Iter 14  Ep 10]  pol=4.2449  val=1.0732  ent=-3.8449

--- Iteration 15: Self-Play ---
--- Iteration 15: Training (Avg Reward: 2.3745) ---
[Iter 15  Ep 1]  pol=4.3315  val=0.7135  ent=-3.8518
[Iter 15  Ep 2]  pol=4.4158  val=0.5374  ent=-3.8637
[Iter 15  Ep 3]  pol=4.1173  val=0.6630  ent=-3.8668
[Iter 15  Ep 4]  pol=4.3806  val=0.6775  ent=-3.8469
[Iter 15  Ep 5]  pol=4.3284  val=0.6984  ent=-3.8526
[Iter 15  Ep 6]  pol=4.4428  val=0.9531  ent=-3.8453
[Iter 15  Ep 7]  pol=4.3217  val=1.2774  ent=-3.8355
[Iter 15  Ep 8]  pol=4.5019  val=1.0969  ent=-3.8441
[Iter 15  Ep 9]  pol=4.5484  val=1.1201  ent=-3.8528
[Iter 15  Ep 10]  pol=4.4175  val=0.7976  ent=-3.8570

--- Iteration 16: Self-Play ---
--- Iteration 16: Training (Avg Reward: 2.3496) ---
[Iter 16  Ep 1]  pol=4.3083  val=1.6736  ent=-3.8628
[Iter 16  Ep 2]  pol=4.4766  val=2.1785  ent=-3.8491
[Iter 16  Ep 3]  pol=4.5341  val=1.9769  ent=-3.8596
[Iter 16  Ep 4]  pol=4.2716  val=2.2167  ent=-3.8619
[Iter 16  Ep 5]  pol=4.2134  val=1.5695  ent=-3.8550
[Iter 16  Ep 6]  pol=4.3119  val=1.2276  ent=-3.8559
[Iter 16  Ep 7]  pol=4.3512  val=1.8498  ent=-3.8687
[Iter 16  Ep 8]  pol=4.3543  val=1.4899  ent=-3.8654
[Iter 16  Ep 9]  pol=4.3165  val=1.2831  ent=-3.8675
[Iter 16  Ep 10]  pol=4.4987  val=1.7342  ent=-3.8572

--- Iteration 17: Self-Play ---
--- Iteration 17: Training (Avg Reward: 2.3408) ---
[Iter 17  Ep 1]  pol=4.1379  val=0.5854  ent=-3.8510
[Iter 17  Ep 2]  pol=4.3905  val=0.5024  ent=-3.8689
[Iter 17  Ep 3]  pol=4.4840  val=0.6230  ent=-3.8710
[Iter 17  Ep 4]  pol=4.3224  val=0.4536  ent=-3.8703
[Iter 17  Ep 5]  pol=4.4038  val=0.4076  ent=-3.8729
[Iter 17  Ep 6]  pol=4.4514  val=0.5917  ent=-3.8907
[Iter 17  Ep 7]  pol=4.3268  val=0.8542  ent=-3.8769
[Iter 17  Ep 8]  pol=4.5830  val=0.9116  ent=-3.8591
[Iter 17  Ep 9]  pol=4.2212  val=0.5920  ent=-3.8794
[Iter 17  Ep 10]  pol=4.4815  val=0.7619  ent=-3.8685

--- Iteration 18: Self-Play ---
--- Iteration 18: Training (Avg Reward: 2.0696) ---
[Iter 18  Ep 1]  pol=4.3521  val=0.9855  ent=-3.8916
[Iter 18  Ep 2]  pol=4.4344  val=1.1913  ent=-3.8785
[Iter 18  Ep 3]  pol=4.3486  val=1.3458  ent=-3.8918
[Iter 18  Ep 4]  pol=4.2103  val=1.0808  ent=-3.8779
[Iter 18  Ep 5]  pol=4.3190  val=1.1714  ent=-3.8673
[Iter 18  Ep 6]  pol=4.2828  val=1.3112  ent=-3.8787
[Iter 18  Ep 7]  pol=4.4132  val=0.9731  ent=-3.8707
[Iter 18  Ep 8]  pol=4.1511  val=1.1247  ent=-3.8973
[Iter 18  Ep 9]  pol=4.2498  val=1.3026  ent=-3.8906
[Iter 18  Ep 10]  pol=4.2111  val=0.9319  ent=-3.8980

--- Iteration 19: Self-Play ---
--- Iteration 19: Training (Avg Reward: 2.2225) ---
[Iter 19  Ep 1]  pol=4.3104  val=1.0437  ent=-3.8755
[Iter 19  Ep 2]  pol=4.2492  val=1.0200  ent=-3.8918
[Iter 19  Ep 3]  pol=4.3931  val=1.1373  ent=-3.8872
[Iter 19  Ep 4]  pol=4.3382  val=1.1416  ent=-3.8865
[Iter 19  Ep 5]  pol=4.3661  val=0.7611  ent=-3.9007
[Iter 19  Ep 6]  pol=4.3161  val=0.8360  ent=-3.8914
[Iter 19  Ep 7]  pol=4.2845  val=2.2142  ent=-3.8762
[Iter 19  Ep 8]  pol=4.3188  val=1.8629  ent=-3.8860
[Iter 19  Ep 9]  pol=4.3128  val=1.8969  ent=-3.8944
[Iter 19  Ep 10]  pol=4.4224  val=1.3303  ent=-3.8851

--- Iteration 20: Self-Play ---
--- Iteration 20: Training (Avg Reward: 2.1493) ---
[Iter 20  Ep 1]  pol=4.2542  val=0.8582  ent=-3.8807
[Iter 20  Ep 2]  pol=4.3786  val=1.1559  ent=-3.8990
[Iter 20  Ep 3]  pol=4.3429  val=1.1142  ent=-3.8902
[Iter 20  Ep 4]  pol=4.5537  val=1.3095  ent=-3.8973
[Iter 20  Ep 5]  pol=4.3557  val=1.2647  ent=-3.8820
[Iter 20  Ep 6]  pol=4.2677  val=1.2248  ent=-3.8966
[Iter 20  Ep 7]  pol=4.3148  val=1.0608  ent=-3.8975
[Iter 20  Ep 8]  pol=4.3686  val=1.2829  ent=-3.9028
[Iter 20  Ep 9]  pol=4.3164  val=1.5879  ent=-3.9029
[Iter 20  Ep 10]  pol=4.2734  val=0.9576  ent=-3.9095

--- Iteration 21: Self-Play ---
--- Iteration 21: Training (Avg Reward: 2.2592) ---
[Iter 21  Ep 1]  pol=4.2928  val=1.0794  ent=-3.8852
[Iter 21  Ep 2]  pol=4.2879  val=0.8061  ent=-3.8976
[Iter 21  Ep 3]  pol=4.3873  val=1.0984  ent=-3.8929
[Iter 21  Ep 4]  pol=4.2916  val=1.2419  ent=-3.8973
[Iter 21  Ep 5]  pol=4.4492  val=0.9070  ent=-3.9024
[Iter 21  Ep 6]  pol=4.3674  val=1.2294  ent=-3.8839
[Iter 21  Ep 7]  pol=4.2632  val=0.8266  ent=-3.9109
[Iter 21  Ep 8]  pol=4.2053  val=1.1724  ent=-3.9105
[Iter 21  Ep 9]  pol=4.4886  val=1.1942  ent=-3.9125
[Iter 21  Ep 10]  pol=4.2899  val=0.8919  ent=-3.9015

--- Iteration 22: Self-Play ---
--- Iteration 22: Training (Avg Reward: 2.3010) ---
[Iter 22  Ep 1]  pol=4.4382  val=0.8573  ent=-3.9100
[Iter 22  Ep 2]  pol=4.2819  val=0.8417  ent=-3.8958
[Iter 22  Ep 3]  pol=4.4550  val=1.0322  ent=-3.9079
[Iter 22  Ep 4]  pol=4.3258  val=1.0790  ent=-3.9058
[Iter 22  Ep 5]  pol=4.3138  val=0.8434  ent=-3.9421
[Iter 22  Ep 6]  pol=4.4681  val=0.8284  ent=-3.9248
[Iter 22  Ep 7]  pol=4.1556  val=1.0636  ent=-3.9156
[Iter 22  Ep 8]  pol=4.2833  val=0.9141  ent=-3.9215
[Iter 22  Ep 9]  pol=4.4807  val=0.8580  ent=-3.9263
[Iter 22  Ep 10]  pol=4.5193  val=0.9451  ent=-3.9154

--- Iteration 23: Self-Play ---
--- Iteration 23: Training (Avg Reward: 2.4890) ---
[Iter 23  Ep 1]  pol=4.2848  val=1.0549  ent=-3.9156
[Iter 23  Ep 2]  pol=4.1774  val=1.3303  ent=-3.9048
[Iter 23  Ep 3]  pol=4.3216  val=0.7934  ent=-3.9147
[Iter 23  Ep 4]  pol=4.4773  val=0.9087  ent=-3.9204
[Iter 23  Ep 5]  pol=4.3535  val=0.8773  ent=-3.9302
[Iter 23  Ep 6]  pol=4.2241  val=0.9725  ent=-3.9240
[Iter 23  Ep 7]  pol=4.4421  val=1.1371  ent=-3.9249
[Iter 23  Ep 8]  pol=4.4934  val=1.1570  ent=-3.9157
[Iter 23  Ep 9]  pol=4.2898  val=0.9915  ent=-3.9326
[Iter 23  Ep 10]  pol=4.2806  val=1.0408  ent=-3.9168

--- Iteration 24: Self-Play ---
--- Iteration 24: Training (Avg Reward: 2.1837) ---
[Iter 24  Ep 1]  pol=4.2815  val=2.0860  ent=-3.9226
[Iter 24  Ep 2]  pol=4.5314  val=1.8662  ent=-3.9154
[Iter 24  Ep 3]  pol=4.1813  val=1.2854  ent=-3.9132
[Iter 24  Ep 4]  pol=4.0653  val=1.5390  ent=-3.9142
[Iter 24  Ep 5]  pol=4.2641  val=1.8723  ent=-3.9335
[Iter 24  Ep 6]  pol=4.2640  val=1.2189  ent=-3.8962
[Iter 24  Ep 7]  pol=4.2802  val=1.4630  ent=-3.9353
[Iter 24  Ep 8]  pol=4.2671  val=1.1794  ent=-3.9096
[Iter 24  Ep 9]  pol=4.4507  val=1.8258  ent=-3.9174
[Iter 24  Ep 10]  pol=4.3986  val=0.9778  ent=-3.9151

--- Iteration 25: Self-Play ---
--- Iteration 25: Training (Avg Reward: 2.2896) ---
[Iter 25  Ep 1]  pol=4.4827  val=1.6271  ent=-3.9291
[Iter 25  Ep 2]  pol=4.3476  val=1.8454  ent=-3.9092
[Iter 25  Ep 3]  pol=4.3712  val=1.3432  ent=-3.9177
[Iter 25  Ep 4]  pol=4.3179  val=1.4040  ent=-3.9221
[Iter 25  Ep 5]  pol=4.2399  val=1.2540  ent=-3.9278
[Iter 25  Ep 6]  pol=4.3808  val=1.4788  ent=-3.9327
[Iter 25  Ep 7]  pol=4.1732  val=1.2657  ent=-3.9331
[Iter 25  Ep 8]  pol=4.3563  val=1.1773  ent=-3.9254
[Iter 25  Ep 9]  pol=4.2875  val=1.1324  ent=-3.9324
[Iter 25  Ep 10]  pol=4.2354  val=1.5471  ent=-3.9243

--- Iteration 26: Self-Play ---
--- Iteration 26: Training (Avg Reward: 2.2227) ---
[Iter 26  Ep 1]  pol=4.3752  val=0.7959  ent=-3.9470
[Iter 26  Ep 2]  pol=4.3141  val=0.5727  ent=-3.9390
[Iter 26  Ep 3]  pol=4.2432  val=0.5084  ent=-3.9447
[Iter 26  Ep 4]  pol=4.2182  val=0.5188  ent=-3.9334
[Iter 26  Ep 5]  pol=4.2062  val=0.6277  ent=-3.9498
[Iter 26  Ep 6]  pol=4.2661  val=0.8436  ent=-3.9527
[Iter 26  Ep 7]  pol=4.2884  val=0.4217  ent=-3.9252
[Iter 26  Ep 8]  pol=4.3238  val=0.6142  ent=-3.9455
[Iter 26  Ep 9]  pol=4.4022  val=0.9691  ent=-3.9335
[Iter 26  Ep 10]  pol=4.1718  val=0.6791  ent=-3.9226

--- Iteration 27: Self-Play ---
--- Iteration 27: Training (Avg Reward: 2.2411) ---
[Iter 27  Ep 1]  pol=4.2952  val=0.8400  ent=-3.9354
[Iter 27  Ep 2]  pol=4.2149  val=1.4151  ent=-3.9420
[Iter 27  Ep 3]  pol=4.2662  val=1.3547  ent=-3.9414
[Iter 27  Ep 4]  pol=4.2416  val=1.3342  ent=-3.9306
[Iter 27  Ep 5]  pol=4.2938  val=1.1801  ent=-3.9357
[Iter 27  Ep 6]  pol=4.3676  val=1.3092  ent=-3.9457
[Iter 27  Ep 7]  pol=4.1445  val=1.8412  ent=-3.9463
[Iter 27  Ep 8]  pol=4.3096  val=1.0998  ent=-3.9318
[Iter 27  Ep 9]  pol=4.2467  val=1.2813  ent=-3.9482
[Iter 27  Ep 10]  pol=4.2941  val=1.0058  ent=-3.9436

--- Iteration 28: Self-Play ---
--- Iteration 28: Training (Avg Reward: 2.2507) ---
[Iter 28  Ep 1]  pol=4.3365  val=1.3564  ent=-3.9452
[Iter 28  Ep 2]  pol=4.2806  val=1.2984  ent=-3.9596
[Iter 28  Ep 3]  pol=4.3697  val=1.1190  ent=-3.9529
[Iter 28  Ep 4]  pol=4.2030  val=1.3778  ent=-3.9491
[Iter 28  Ep 5]  pol=4.1390  val=1.2574  ent=-3.9297
[Iter 28  Ep 6]  pol=4.2699  val=1.1727  ent=-3.9522
[Iter 28  Ep 7]  pol=4.3078  val=1.2870  ent=-3.9540
[Iter 28  Ep 8]  pol=4.3004  val=1.2092  ent=-3.9573
[Iter 28  Ep 9]  pol=4.1541  val=0.9464  ent=-3.9520
[Iter 28  Ep 10]  pol=4.3338  val=1.0880  ent=-3.9429

--- Iteration 29: Self-Play ---
--- Iteration 29: Training (Avg Reward: 2.3255) ---
[Iter 29  Ep 1]  pol=4.3938  val=1.1520  ent=-3.9514
[Iter 29  Ep 2]  pol=4.2380  val=0.9882  ent=-3.9525
[Iter 29  Ep 3]  pol=4.1733  val=1.1427  ent=-3.9609
[Iter 29  Ep 4]  pol=4.2207  val=1.0714  ent=-3.9628
[Iter 29  Ep 5]  pol=4.2046  val=1.4395  ent=-3.9501
[Iter 29  Ep 6]  pol=4.2989  val=0.9017  ent=-3.9679
[Iter 29  Ep 7]  pol=4.2749  val=0.9430  ent=-3.9385
[Iter 29  Ep 8]  pol=4.1984  val=0.9546  ent=-3.9458
[Iter 29  Ep 9]  pol=4.2537  val=1.2613  ent=-3.9644
[Iter 29  Ep 10]  pol=4.3287  val=1.9565  ent=-3.9609

--- Iteration 30: Self-Play ---
--- Iteration 30: Training (Avg Reward: 2.1796) ---
[Iter 30  Ep 1]  pol=4.3832  val=1.1397  ent=-3.9609
[Iter 30  Ep 2]  pol=4.3125  val=1.3043  ent=-3.9644
[Iter 30  Ep 3]  pol=4.2772  val=0.8299  ent=-3.9654
[Iter 30  Ep 4]  pol=4.1932  val=0.9179  ent=-3.9571
[Iter 30  Ep 5]  pol=4.2249  val=1.2613  ent=-3.9571
[Iter 30  Ep 6]  pol=4.2127  val=1.5351  ent=-3.9709
[Iter 30  Ep 7]  pol=4.4451  val=0.9073  ent=-3.9614
[Iter 30  Ep 8]  pol=4.4491  val=1.3135  ent=-3.9551
[Iter 30  Ep 9]  pol=4.2789  val=1.2613  ent=-3.9675
[Iter 30  Ep 10]  pol=4.0954  val=1.0014  ent=-3.9646

--- Iteration 31: Self-Play ---
--- Iteration 31: Training (Avg Reward: 2.0590) ---
[Iter 31  Ep 1]  pol=4.2923  val=1.0327  ent=-3.9589
[Iter 31  Ep 2]  pol=4.2678  val=1.3407  ent=-3.9665
[Iter 31  Ep 3]  pol=4.4131  val=1.0357  ent=-3.9634
[Iter 31  Ep 4]  pol=4.2844  val=1.1231  ent=-3.9650
[Iter 31  Ep 5]  pol=4.3140  val=1.5098  ent=-3.9633
[Iter 31  Ep 6]  pol=4.2451  val=1.5382  ent=-3.9691
[Iter 31  Ep 7]  pol=4.1666  val=1.3949  ent=-3.9617
[Iter 31  Ep 8]  pol=4.2468  val=1.2305  ent=-3.9669
[Iter 31  Ep 9]  pol=4.2336  val=1.1801  ent=-3.9602
[Iter 31  Ep 10]  pol=4.2453  val=1.5231  ent=-3.9728

--- Iteration 32: Self-Play ---
--- Iteration 32: Training (Avg Reward: 2.1196) ---
[Iter 32  Ep 1]  pol=4.2881  val=0.9876  ent=-3.9648
[Iter 32  Ep 2]  pol=4.3558  val=0.9754  ent=-3.9754
[Iter 32  Ep 3]  pol=4.2885  val=1.0338  ent=-3.9661
[Iter 32  Ep 4]  pol=4.3029  val=0.8836  ent=-3.9830
[Iter 32  Ep 5]  pol=4.1763  val=1.3969  ent=-3.9695
[Iter 32  Ep 6]  pol=4.1712  val=1.0245  ent=-3.9759
[Iter 32  Ep 7]  pol=4.2141  val=0.7831  ent=-3.9820
[Iter 32  Ep 8]  pol=4.1923  val=1.0825  ent=-3.9778
[Iter 32  Ep 9]  pol=4.2876  val=1.2293  ent=-3.9759
[Iter 32  Ep 10]  pol=4.2747  val=0.9580  ent=-3.9654

--- Iteration 33: Self-Play ---
--- Iteration 33: Training (Avg Reward: 2.2542) ---
[Iter 33  Ep 1]  pol=4.1426  val=1.3836  ent=-3.9812
[Iter 33  Ep 2]  pol=4.1879  val=0.9876  ent=-3.9806
[Iter 33  Ep 3]  pol=4.2724  val=1.4033  ent=-3.9764
[Iter 33  Ep 4]  pol=4.1270  val=1.1680  ent=-3.9798
[Iter 33  Ep 5]  pol=4.1984  val=0.7494  ent=-3.9640
[Iter 33  Ep 6]  pol=4.2742  val=1.0966  ent=-3.9659
[Iter 33  Ep 7]  pol=4.2971  val=0.8339  ent=-3.9730
[Iter 33  Ep 8]  pol=4.3272  val=1.1641  ent=-3.9798
[Iter 33  Ep 9]  pol=4.1807  val=0.9283  ent=-3.9826
[Iter 33  Ep 10]  pol=4.1474  val=1.4611  ent=-3.9738

--- Iteration 34: Self-Play ---
--- Iteration 34: Training (Avg Reward: 2.3842) ---
[Iter 34  Ep 1]  pol=4.2154  val=0.8757  ent=-3.9816
[Iter 34  Ep 2]  pol=4.2248  val=0.8632  ent=-3.9771
[Iter 34  Ep 3]  pol=4.3652  val=0.9357  ent=-3.9781
[Iter 34  Ep 4]  pol=4.2299  val=0.8644  ent=-3.9859
[Iter 34  Ep 5]  pol=4.1856  val=0.7973  ent=-3.9755
[Iter 34  Ep 6]  pol=4.3123  val=1.2297  ent=-3.9795
[Iter 34  Ep 7]  pol=4.2198  val=1.0029  ent=-3.9874
[Iter 34  Ep 8]  pol=4.1157  val=1.2103  ent=-3.9808
[Iter 34  Ep 9]  pol=4.2342  val=0.9571  ent=-3.9754
[Iter 34  Ep 10]  pol=4.2912  val=1.1308  ent=-3.9861

--- Iteration 35: Self-Play ---
--- Iteration 35: Training (Avg Reward: 2.3138) ---
[Iter 35  Ep 1]  pol=4.1481  val=1.0675  ent=-3.9904
[Iter 35  Ep 2]  pol=4.2570  val=1.1054  ent=-3.9869
[Iter 35  Ep 3]  pol=4.1739  val=1.1475  ent=-3.9820
[Iter 35  Ep 4]  pol=4.1608  val=0.7456  ent=-3.9746
[Iter 35  Ep 5]  pol=4.2090  val=0.9199  ent=-3.9865
[Iter 35  Ep 6]  pol=4.1909  val=1.1845  ent=-3.9795
[Iter 35  Ep 7]  pol=4.2120  val=2.0407  ent=-3.9930
[Iter 35  Ep 8]  pol=4.2454  val=3.1415  ent=-3.9727
[Iter 35  Ep 9]  pol=4.1061  val=3.5212  ent=-3.9688
[Iter 35  Ep 10]  pol=4.3374  val=3.4495  ent=-3.9828

--- Iteration 36: Self-Play ---
--- Iteration 36: Training (Avg Reward: 2.3410) ---
[Iter 36  Ep 1]  pol=4.2348  val=3.5373  ent=-3.9836
[Iter 36  Ep 2]  pol=4.2164  val=1.7692  ent=-3.9907
[Iter 36  Ep 3]  pol=4.2796  val=1.3454  ent=-3.9914
[Iter 36  Ep 4]  pol=4.3190  val=1.0539  ent=-3.9834
[Iter 36  Ep 5]  pol=4.2956  val=2.0200  ent=-3.9953
[Iter 36  Ep 6]  pol=4.2566  val=2.2889  ent=-3.9873
[Iter 36  Ep 7]  pol=4.2063  val=1.8315  ent=-3.9760
[Iter 36  Ep 8]  pol=4.1911  val=1.5956  ent=-3.9868
[Iter 36  Ep 9]  pol=4.2926  val=2.0146  ent=-3.9829
[Iter 36  Ep 10]  pol=4.2271  val=1.4136  ent=-3.9821

--- Iteration 37: Self-Play ---
--- Iteration 37: Training (Avg Reward: 2.3695) ---
[Iter 37  Ep 1]  pol=4.1734  val=1.3727  ent=-3.9896
[Iter 37  Ep 2]  pol=4.3037  val=1.7184  ent=-3.9922
[Iter 37  Ep 3]  pol=4.3100  val=0.7599  ent=-3.9878
[Iter 37  Ep 4]  pol=4.3098  val=1.7644  ent=-3.9830
[Iter 37  Ep 5]  pol=4.0669  val=1.1638  ent=-3.9886
[Iter 37  Ep 6]  pol=4.2283  val=0.8961  ent=-3.9903
[Iter 37  Ep 7]  pol=4.1812  val=2.5831  ent=-3.9801
[Iter 37  Ep 8]  pol=4.2102  val=3.6626  ent=-3.9902
[Iter 37  Ep 9]  pol=4.1871  val=4.9562  ent=-3.9842
[Iter 37  Ep 10]  pol=4.3309  val=5.4747  ent=-3.9866

--- Iteration 38: Self-Play ---
--- Iteration 38: Training (Avg Reward: 2.2923) ---
[Iter 38  Ep 1]  pol=4.1359  val=4.1430  ent=-3.9879
[Iter 38  Ep 2]  pol=4.0746  val=2.9047  ent=-3.9789
[Iter 38  Ep 3]  pol=4.1685  val=1.8998  ent=-3.9853
[Iter 38  Ep 4]  pol=4.1922  val=0.9816  ent=-3.9914
[Iter 38  Ep 5]  pol=4.1262  val=1.3855  ent=-3.9852
[Iter 38  Ep 6]  pol=4.1805  val=1.4531  ent=-4.0033
[Iter 38  Ep 7]  pol=4.3503  val=1.2210  ent=-3.9921
[Iter 38  Ep 8]  pol=4.2400  val=0.7239  ent=-4.0046
[Iter 38  Ep 9]  pol=4.2245  val=1.0634  ent=-3.9902
[Iter 38  Ep 10]  pol=4.2349  val=0.7329  ent=-3.9865

--- Iteration 39: Self-Play ---
--- Iteration 39: Training (Avg Reward: 2.4332) ---
[Iter 39  Ep 1]  pol=4.3409  val=0.9266  ent=-3.9838
[Iter 39  Ep 2]  pol=4.2968  val=1.2566  ent=-3.9976
[Iter 39  Ep 3]  pol=4.1736  val=1.1406  ent=-3.9850
[Iter 39  Ep 4]  pol=4.2676  val=0.9441  ent=-3.9968
[Iter 39  Ep 5]  pol=4.3002  val=1.2542  ent=-3.9736
[Iter 39  Ep 6]  pol=4.1643  val=1.0679  ent=-3.9881
[Iter 39  Ep 7]  pol=4.1584  val=1.6104  ent=-3.9840
[Iter 39  Ep 8]  pol=4.2075  val=1.2433  ent=-3.9801
[Iter 39  Ep 9]  pol=4.2429  val=1.0658  ent=-3.9873
[Iter 39  Ep 10]  pol=4.1638  val=1.3880  ent=-3.9844

ðŸ“ˆ Curva di training salvata in â†’ loss_curve.png


PPL modello potato: 2058.89
Sparsity finale   : 31.25%
ðŸ”–  plot salvato in â†’ final_gate_state.png
